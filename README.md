# Home_Sales
Module_22_Challenge
I created a New repository called Home_Sales, I cloned the new repository to my computer. I renamed the Home_Sales_starter_Code.ipynb as Home_Sales.ipynb. I imported the necessary PySpark SQL functions. I read the home_sales_revised.csv data in the starter code into a Spark Dataframe. I temporary table called home_sales. I answered the following questions:  what is the average price for a four-bedroom house per year, what is the average price of a home for each year the home was built, that hsa three bedrooms and three bathrooms, what is the average price of a home for each year the home was built, that has three bedrooms and three bathrooms, two floors, and is greater than or equal to 2,000 square feet?, What is the average price of a home per view rating having an average home price great than $350,000? I determined the run time for this query, and round off my answer to two decimals. I cached my temporsry table home_sales. Using the cached data, I ran the last query that calculates the average price of a home per view rating having an average home price greater than or eqaul to $350,000. I determined the run time and comapred it to the uncached runtime. I partitioned by the date_built field on the formatted parquet home sales data. I created a temporary table for the parquet data. I ran the last query that calculates the average price of a home per view rating having an average home price greater than or equal to $350,000. I determined the run time and compared it to uncached runtime. I uncached the home_sales temporary table. I had verified that the home_sales temporary table is uncached using PySpark. 
